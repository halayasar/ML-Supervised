{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Assignment 1: $k$-nearest neighbors</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Copyrighting and Fare Use</h2>\n",
    "\n",
    "This material, no matter whether in printed or electronic form,\n",
    "may be used for personal and non-commercial educational use\n",
    "only. Any reproduction of this material, no matter whether as a\n",
    "whole or in parts, no matter whether in printed or in electronic\n",
    "form, requires explicit prior acceptance of the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Automatic Testing Guidelines</h2>\n",
    "\n",
    "Automatic unittesting requiers you, as a student, to submit notebook which contains strictly defined objects.\n",
    "Strictness of definition consists of unified shapes, dtypes, variable names and more.<br>\n",
    "Within the notebook we provide detailed instruction which you may want to follow, in order to maximise your final grade.\n",
    "\n",
    "**Name your notebook properly**, follow the pattern in template name:\n",
    "\n",
    "**Assignment_N_NameSurname_matrnumber**\n",
    "<ol>\n",
    "    <li>N - number of assignment</li>\n",
    "    <li>NameSurname - your full name where evry part of the name strats from capital letter, no spaces</li>\n",
    "    <li>matrnumber - you student number on ID card (without k)</li>\n",
    "</ol>\n",
    "\n",
    "Adding cells might badly influence your sumbission, in case if implementations in cells will depend on unexpected ones.\n",
    "You may notice, that most cells are tagged, that is the way for unittest routine to recognise them.\n",
    "We highly recommend you to develop your code within provided cells.\n",
    "\n",
    "**If you delete any cell or tag**, it will be hard to evaluate respective part of assingment.\n",
    "\n",
    "**Please be careful**, and may force be with you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 1: Visualization</h2>\n",
    "\n",
    "Visualize the data stored in `DataSet1.csv` with a scatter plot.<br>\n",
    "The first two columns are the features which hold the x and y coordinates of the data.<br>\n",
    "The last column provides the labels of the data. Use different colors for different labels.<br>\n",
    "Always label the axes of all your plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Code 1 (20 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "dataset"
    ]
   },
   "outputs": [],
   "source": [
    "# read data, split into X(features) and y(labels)\n",
    "Z = np.genfromtxt('DataSet1.csv', delimiter=';')\n",
    "X, y = Z[:,:-1], Z[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "plot1"
    ]
   },
   "outputs": [],
   "source": [
    "#your code goes here ↓↓↓\n",
    "plot1 = None\n",
    "xx = X[:,0]\n",
    "yy = X[:,1]\n",
    "\n",
    "plt.title('DataSet1')\n",
    "plt.xlabel('x coordinates')\n",
    "plt.ylabel('y coordinates')\n",
    "plt.scatter(xx, yy, c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Question 1 (5 points):</h3>\n",
    "\n",
    "***Which of the following statements about $k$-nearest neighbors is correct?***<br>\n",
    "(Multiple answers might be correct)\n",
    "\n",
    "a_) requires long training time <br>\n",
    "b_) not suited for large datasets <br>\n",
    "c_) sensitive to the rescaling of individual features <br>\n",
    "d_) has many trainable model parameters <br>\n",
    "\n",
    "To answer the question assign to variables in the nex cell **True** or **False** boolean values. \n",
    "To earn points **assign values to all variables**.<br>\n",
    "**NOTE** Do not reuse these variable names. They are used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "question1"
    ]
   },
   "outputs": [],
   "source": [
    "#examples for you\n",
    "example_of_true_variable = True\n",
    "example_of_false_variable = False\n",
    "\n",
    "#your answers go here ↓↓↓\n",
    "a_=False\n",
    "b_=True\n",
    "c_=True\n",
    "d_=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 2: Training the model</h2>\n",
    "\n",
    "Use $k$-nearest neighbors classifiers with $k \\in \\{1,3,5,...,177,179\\}$.<br>\n",
    "Either use the `KNeighborsClassifier` function from `sklearn` or implement it on your own.<br>\n",
    "Estimate the generalization error with **zero-one loss** via the empirical risk (see lecture Unit 1, p.25 ff.) and use **10-fold** cross validation.<br>\n",
    "Visualize your results, i.e., plot the error (as defined above) vs. $k$ of $k$-nearest neighbors classifiers.\n",
    "<br>\n",
    "<br>\n",
    "Hint: implement a function that takes the feature matrix ($X$), the label vector ($y$), the number of CV folds ($nf$), $k$ of the $k$-nearest neighbors classifiers ($k$) as arguments:<br>\n",
    "`def evaluate_kNN(X,y,nf,k):`<br>\n",
    "It should return the mean error (as defined above) over the CV folds.\n",
    "\n",
    "<h3 style=\"color:rgb(210,90,80)\">Code 2 (15 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "evaluate_knn"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, zero_one_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_kNN(X,y,kfold,n_neighbors): \n",
    "    accuracies = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "    \n",
    "    classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    metrics.accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    score = cross_val_score(classifier, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    accuracies.append(score.mean())      \n",
    "       \n",
    "    zero_one = 1 - np.asarray(accuracies)\n",
    "    \n",
    "    return zero_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "plot2"
    ]
   },
   "outputs": [],
   "source": [
    "#define error_holder via calling evaluate_kNN function.\n",
    "error_holder=[]\n",
    "for k in range(1, 179):\n",
    "        #k=k+1\n",
    "        error = evaluate_kNN(X, y, kfold=10, n_neighbors=k)\n",
    "        \n",
    "        error_holder.append(error)      \n",
    "#implement the plot as described in the task\n",
    "plot2 = None\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, 179), error_holder)\n",
    "plt.title('Error Rate vs k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('generalisation error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Question 2 (10 points):</h3>\n",
    "\n",
    "<i><b>Thinking of model complexity as the ability of the model to fit to noise, what choice of $k$ gives complex models? Why?</b></i><br>\n",
    "(Multiple answers might be correct)\n",
    "\n",
    "e_) Model complexity increases with increasing $k$, as larger $k$ means the model has more parameters. <br>\n",
    "f_)  Model complexity increases with increasing $k$, as larger $k$ means that more neighbors influence the decision. <br>\n",
    "g_)  Model complexity increases with decreasing $k$, as smaller $k$ means that fewer neighbors influence the decision. <br>\n",
    "h_)  Model complexity increases with decreasing $k$, as smaller $k$ means the model has fewer parameters. <br>\n",
    "\n",
    "To answer the question assign to variables in the nex cell **True** or **False** boolean values. \n",
    "To earn points **assign values to all variables**.<br>\n",
    "**NOTE** Do not reuse these variable names. They are used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "question2_1"
    ]
   },
   "outputs": [],
   "source": [
    "#examples for you\n",
    "example_of_true_variable = True\n",
    "example_of_false_variable = False\n",
    "\n",
    "#your answers go here ↓↓↓\n",
    "e_=False\n",
    "f_=False\n",
    "g_=True\n",
    "h_=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>For the data above, how does the error develop with the model complexity? Why? Look again at the data - do the labels appear to be noisy?</b></i>\n",
    "<br>(Multiple answers might be correct)\n",
    "\n",
    "\n",
    "i_) The error increases with increasing $k$, as there is hardly any noise in the data <br>\n",
    "j_) The error increases with increasing $k$, as there is a lot of noise in the data <br>\n",
    "k_) The error increases with decreasing $k$, as there is hardly any noise in the data <br>\n",
    "l_) The error increases with decreasing $k$, as there is a lot of noise in the data <br>\n",
    "\n",
    "To answer the question assign to variables in the nex cell **True** or **False** boolean values. \n",
    "To earn points **assign values to all variables**.<br>\n",
    "**NOTE** Do not reuse these variable names. They are used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "question2_2"
    ]
   },
   "outputs": [],
   "source": [
    "#examples for you\n",
    "example_of_true_variable = True\n",
    "example_of_false_variable = False\n",
    "\n",
    "#your answers go here ↓↓↓\n",
    "i_=False\n",
    "j_=False\n",
    "k_=False\n",
    "l_=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 3: Add noise to labels</h2>\n",
    "\n",
    "Write a function **flip(y)**, which will take labels vector **y** as an argument, <br> flip the sign of the labels randomly with probability of $\\frac{1}{7}$, and return a **new** labels vector. \n",
    "\n",
    "Use the random seed given below. <br>Perform the same steps as before, i.e. plot the data and plot the error (estimated via the empirical risk) vs. $k$ for **10-fold** cross validation.\n",
    "\n",
    "<h3 style=\"color:rgb(210,90,80)\">Code 3 (15 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "flip"
    ]
   },
   "outputs": [],
   "source": [
    "#your code goes here ↓↓↓\n",
    "\"\"\"\n",
    "Function flip hints:\n",
    "@param y, np array, labels vector\n",
    "@returns np.array of the same shape as original y.\n",
    "\n",
    "Please use this function template and don't change function name.\n",
    "\"\"\"\n",
    "def flip(y):\n",
    "    np.random.seed(1234)\n",
    "    y_noise = y.copy()\n",
    "\n",
    "    for i in range(len(y_noise)):\n",
    "        if rand() < 1/7: \n",
    "            y_noise[i] = -y_noise[i]\n",
    "\n",
    "    return y_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "plot3"
    ]
   },
   "outputs": [],
   "source": [
    "#define new y vector by calling flip function\n",
    "y_fl = flip(y)\n",
    "\n",
    "\n",
    "#perform evaluation on a new data\n",
    "#redefine error_holder via calling evaluate_kNN function.\n",
    "error_holder=[]\n",
    "for k in range(1, 179):\n",
    "        #k=k+1\n",
    "        error = evaluate_kNN(X, y, kfold=10, n_neighbors=k)\n",
    "        \n",
    "        error_holder.append(error)  \n",
    "#your plotting code goes here ↓↓↓\n",
    "plot3 = None\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1,179), error_holder)\n",
    "plt.title('New Error Rate vs k of randomly flipped data')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('generalization error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Question 3 (10 points)</h3>\n",
    "\n",
    "***Which differences do you observe?<br>\n",
    "Which conclusions do you draw from that?***\n",
    "<br>(Multiple answers might be correct)\n",
    "\n",
    "\n",
    "n_) The two classes are still well seperable and have nearly no overlap <br>\n",
    "m_)  The two classes are now less seperable and have a larger overlap  <br>\n",
    "\n",
    "o_)  Random label flipping brings noise into the data <br>\n",
    "p_)  Random label flipping simply swaps data, but no significant changes <br>\n",
    "\n",
    "q_)  Very small values of $k$ correspond to too low model complexity (underfitting) <br>\n",
    "r_)  Very small values of $k$ correspond to too high model complexity (overfitting) <br>\n",
    "s_)  Very large values of $k$ correspond to too low model complexity (underfitting) <br>\n",
    "t_)  Very large values of $k$ correspond to too high model complexity (overfitting) <br>\n",
    "\n",
    "u_)  Overall, the error remains nearly unchanged compared to the original data set. <br>\n",
    "v_)  Overall, the error increases compared to the original data set. <br>\n",
    "\n",
    "To answer the question assign to variables in the nex cell **True** or **False** boolean values. \n",
    "To earn points **assign values to all variables**.\n",
    "<br>\n",
    "**NOTE** Do not reuse these variable names. They are used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "question3"
    ]
   },
   "outputs": [],
   "source": [
    "#examples for you\n",
    "example_of_true_variable = True\n",
    "example_of_false_variable = False\n",
    "\n",
    "#your answers go here ↓↓↓\n",
    "n_=True\n",
    "m_=False\n",
    "\n",
    "o_=False\n",
    "p_=True\n",
    "\n",
    "q_=False\n",
    "r_=True\n",
    "s_=True\n",
    "t_=False\n",
    "\n",
    "u_=True\n",
    "v_=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 4: $k$-NN in higher dimensions</h2>\n",
    "\n",
    "Going back to **unflipped labels**. \n",
    "Write a function **add_features(X)** which will modify feature matrix X by adding 4 additional features. Each feature is uniformly distributed between 0 an 1.<br>\n",
    "\n",
    "\n",
    "As before plot the error versus $k$ for **10 folds** for each feature matrix X with one, two, three and four incrementally added features which we denote as $f$. <br>\n",
    "Additionaly plot mean error versus $f$ for $k$ = 11.<br>\n",
    "As a result you need to show 5 plots.\n",
    "\n",
    "<h3 style=\"color:rgb(210,90,80)\">Code 4 (20 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "add_features"
    ]
   },
   "outputs": [],
   "source": [
    "#your code goes here ↓↓↓\n",
    "\"\"\"\n",
    "Function add_features hints:\n",
    "@param X, np ndarray, feature matrix\n",
    "@returns np.array with the same properties as matrix X but new shape.\n",
    "\n",
    "Please use this function template and don't change function name.\"\"\"\n",
    "def add_features(X):\n",
    "    np.random.seed(1234) \n",
    "    \n",
    "    rFeatures = np.random.uniform(low=0, high=1, size=(X.shape[0], 4))\n",
    "    X_new = np.concatenate((X, rFeatures), axis=1)\n",
    "    \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "plot4"
    ]
   },
   "outputs": [],
   "source": [
    "#define new feature matrix by calling add_features function\n",
    "X_new = add_features(X)\n",
    "Xf1 = X_new[:,:2]\n",
    "Xf2 = X_new[:,:3]\n",
    "Xf3 = X_new[:,:4]\n",
    "Xf4 = X_new[:,:]\n",
    "\n",
    "error_holder=[]\n",
    "for k in range(1,11):\n",
    "        k=k+1\n",
    "        error = evaluate_kNN(X_new, y, kfold=10, n_neighbors=k)\n",
    "        error_holder.append(error) \n",
    "\n",
    "error_holderf1=[]\n",
    "for k in range(1, 11):\n",
    "        k=k+1\n",
    "        error = evaluate_kNN(Xf1, y, kfold=10, n_neighbors=k)\n",
    "        error_holderf1.append(error) \n",
    "        \n",
    "error_holderf2=[]\n",
    "for k in range(1, 11):\n",
    "        k=k+1\n",
    "        error = evaluate_kNN(Xf2, y, kfold=10, n_neighbors=k)\n",
    "        error_holderf2.append(error) \n",
    "\n",
    "error_holderf3=[]\n",
    "for k in range(1, 11):\n",
    "        k=k+1\n",
    "        error = evaluate_kNN(Xf3, y, kfold=10, n_neighbors=k)\n",
    "        error_holderf3.append(error) \n",
    "\n",
    "error_holderf4=[]\n",
    "for k in range(1, 11):\n",
    "        k=k+1\n",
    "        error = evaluate_kNN(Xf4, y, kfold=10, n_neighbors=k)\n",
    "        error_holderf4.append(error) \n",
    "        \n",
    "#show 5 plots\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1,11), error_holder)\n",
    "plt.title('Error Rate vs k with 4 Noise Features')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('generalization error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1,11), error_holderf1)\n",
    "plt.title('Error Rate vs k with f1')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('generalization error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1,11), error_holderf2)\n",
    "plt.title('Error Rate vs k with f2')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('generalization error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1,11), error_holderf3)\n",
    "plt.title('Error Rate vs k with f3')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('generalization error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1,11), error_holderf4)\n",
    "plt.title('Error Rate vs k with f4')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('generalization error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Question 4 (5 points)</h3>\n",
    "\n",
    "***Try to explain possible changes of the error.***\n",
    "<br>(Multiple answers might be correct)\n",
    "\n",
    "w_) $k$-nearest neighbors is robust against randomly added further features; noise is filtered out <br>\n",
    "x_)  $k$-nearest neighbors is not robust aginst randomly added further features; noise is not filtered out\n",
    "\n",
    "y_)  The more noise (extra dimensions), the lower the optimal $k$ <br>\n",
    "z_)  The more noise (extra dimensions), the higher the optimal $k$ <br>\n",
    "\n",
    "To answer the question assign to variables in the nex cell **True** or **False** boolean values. \n",
    "To earn points **assign values to all variables**.<br>\n",
    "**NOTE** Do not reuse these variable names. They are used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "question4"
    ]
   },
   "outputs": [],
   "source": [
    "#examples for you\n",
    "example_of_true_variable = True\n",
    "example_of_false_variable = False\n",
    "\n",
    "#your answers go here ↓↓↓n=True\n",
    "w_=True\n",
    "x_=False\n",
    "\n",
    "y_=True\n",
    "z_=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Tehnical cells</h2>\n",
    "\n",
    "The cells below are needed for efficient unittesting.\n",
    "Do not delete or change in order to receive proper evaluation.<br>\n",
    "Executability check might help you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tech"
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate_kNN_tl(X,y,kfold,n_neighbors):\n",
    "    try:\n",
    "        return evaluate_kNN(X,y,kfold,n_neighbors)*1\n",
    "    except:\n",
    "        raise ValueError(\"evaluate_kNN does not return number\")\n",
    "\n",
    "def flip_tl(y):\n",
    "    try:\n",
    "        return flip(y).tolist()\n",
    "    except:\n",
    "        raise ValueError(\"flip does not return np array\")\n",
    "\n",
    "def add_features_tl(X):\n",
    "    try:\n",
    "        return add_features(X).tolist()\n",
    "    except:\n",
    "        raise ValueError(\"add_features does not return np array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exec"
    ]
   },
   "outputs": [],
   "source": [
    "#executability check\n",
    "evaluate_kNN_tl(X,y,10,5)\n",
    "flip_tl(y)\n",
    "add_features_tl(X)\n",
    "print(\"Executable\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
